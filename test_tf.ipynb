{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_tf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vu3bpn/machine_learn_1/blob/master/test_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4QRbzh_woPma",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yn-YobvFopCb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f1 = lambda x: np.sin(x)\n",
        "f2 = lambda x: np.sin(x)*np.cos(x)\n",
        "f3 = lambda x: np.sin(x)**2\n",
        "func_list = [f1,f2,f3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TGSRq2D3paX2",
        "colab_type": "code",
        "outputId": "6c4e44bb-7135-494f-9d66-0509b97e9b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "n_f = 20000\n",
        "n_s = 10\n",
        "vector_list =[]\n",
        "out_list = []\n",
        "for batch_no  in range(n_f):\n",
        "  idx= 0 \n",
        "  for func_1 in func_list:\n",
        "    x = np.random.random(n_s)*np.pi*2\n",
        "    y = list(map(func_1,x))\n",
        "    vector_list.append([np.array([x,y]).flatten()])\n",
        "    out_list.append([idx])\n",
        "    idx+=1\n",
        "    if batch_no == 0:\n",
        "      plt.scatter(x,y)\n",
        "vector_array = np.array(vector_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFKCAYAAAAwrQetAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3b42149d30>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "nFKft9rqumsb",
        "colab_type": "code",
        "outputId": "a8de5dd6-4e3b-4c47-ded2-2346f4fd4abf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(tf.one_hot(out_list,depth=3))\n",
        "#print(vector_array)\n",
        "print(vector_array.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"one_hot:0\", shape=(60000, 1, 3), dtype=float32)\n",
            "(60000, 1, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8LGspI6OueqT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#creating and compiling the model"
      ]
    },
    {
      "metadata": {
        "id": "SfWV1ixbru6k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1 = tf.keras.models.Sequential()\n",
        "model1.add(tf.layers.Dense(10,input_shape=(1,2*n_s)))\n",
        "model1.add(tf.layers.Dense(5,activation='relu'))\n",
        "model1.add(tf.layers.Dense(3,activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x1u-t8FntMvo",
        "colab_type": "code",
        "outputId": "067c73d8-bdfe-4911-fae5-c34df703b896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer = 'adam', loss = 'categorical_crossentropy')\n",
        "print(model1.summary())\n",
        "print(model1.output_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 1, 10)             210       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1, 5)              55        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1, 3)              18        \n",
            "=================================================================\n",
            "Total params: 283\n",
            "Trainable params: 283\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "(None, 1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Anh4b1xoqlR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#train the model"
      ]
    },
    {
      "metadata": {
        "id": "ZJnEM6v4PZpW",
        "colab_type": "code",
        "outputId": "39ea948d-c5d0-4bbf-f12e-b4bae393d148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6834
        }
      },
      "cell_type": "code",
      "source": [
        "#help(model1.fit)\n",
        "model1.fit(vector_array,tf.one_hot(out_list,depth=3),steps_per_epoch=100,epochs=200,shuffle = True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.2225\n",
            "Epoch 2/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 3/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 4/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 5/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 6/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 7/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 8/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 9/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 10/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 11/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 12/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 13/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 14/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 15/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 16/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 17/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 18/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 19/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 20/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 21/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 22/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 23/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 24/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 25/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 26/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 27/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 28/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 29/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 30/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 31/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 32/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 33/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 34/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 35/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 36/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 37/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 38/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 39/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 40/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 41/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 42/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 43/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 44/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 45/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 46/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 47/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 48/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 49/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 50/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 51/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 52/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 53/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 54/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 55/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 56/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 57/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 58/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 59/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 60/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 61/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 62/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 63/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 64/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 65/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 66/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 67/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 68/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 69/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 70/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 71/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 72/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 73/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 74/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 75/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 76/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 77/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 78/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 79/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 80/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 81/200\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2225\n",
            "Epoch 82/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 83/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 84/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 85/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 86/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 87/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 88/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 89/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 90/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 91/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 92/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 93/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 94/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 95/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 96/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 97/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 98/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 99/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 100/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 101/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 102/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 103/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 104/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 105/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 106/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 107/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 108/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 109/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 110/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 111/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 112/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 113/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 114/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 115/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 116/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 117/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 118/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 119/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 120/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 121/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 122/200\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2225\n",
            "Epoch 123/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 124/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 125/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 126/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 127/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 128/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 129/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 130/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 131/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 132/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 133/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 134/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 135/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 136/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 137/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 138/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 139/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 140/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 141/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 142/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 143/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 144/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 145/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 146/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 147/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 148/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 149/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 150/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 151/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 152/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 153/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 154/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 155/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 156/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 157/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 158/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 159/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 160/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 161/200\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2225\n",
            "Epoch 162/200\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2225\n",
            "Epoch 163/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 164/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 165/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 166/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 167/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 168/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 169/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 170/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 171/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 172/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 173/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 174/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 175/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 176/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 177/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 178/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 179/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 180/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 181/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 182/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 183/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 184/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 185/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 186/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 187/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 188/200\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2225\n",
            "Epoch 189/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 190/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 191/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 192/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 193/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 194/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 195/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 196/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 197/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 198/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 199/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n",
            "Epoch 200/200\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2225\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3b3ac3d2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "uQxC_1VBo2tP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vector_list_verify =[]\n",
        "val_list = [0,1,2,2,1,0]\n",
        "for func_idx in val_list:\n",
        "  func_1 = func_list[func_idx]\n",
        "  x = np.random.random(n_s)*np.pi*2\n",
        "  y = list(map(func_1,x))\n",
        "  feat_vect = np.array([np.array([x,y]).flatten()])\n",
        "  out = model1.predict(np.array([feat_vect]))\n",
        "  print(func_idx,out,np.argmax(out.squeeze()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PoGvHYSt9pGP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "28371b89-8fab-4af7-fe52-987cf193c08b"
      },
      "cell_type": "code",
      "source": [
        "val_nf = 200\n",
        "val_vect_list =[]\n",
        "val_out_list =[]\n",
        "for batch_no  in range(val_nf):\n",
        "  idx = 0\n",
        "  for func_1 in func_list:\n",
        "    x = np.random.random(n_s)*np.pi*2\n",
        "    y = list(map(func_1,x))\n",
        "    val_vect_list.append([np.array([x,y]).flatten()])\n",
        "    val_out_list.append([idx])\n",
        "    idx+=1\n",
        "val_vect_array = np.array(val_vect_list)\n",
        "#res = model1.evaluate(val_vect_array,tf.one_hot(val_out_list,depth=3),steps=10)\n",
        "val_out = model1.predict(val_vect_array)\n",
        "val_out_index = list(map(lambda x:np.argmax(x), val_out))\n",
        "#con_mat = tf.confusion_matrix( ,val_out_list)\n",
        "\n",
        "print(len(val_out_index))\n",
        "print(len(np.array(val_out_list).flatten()))\n",
        "con_mat = tf.confusion_matrix(labels = np.array(val_out_list).flatten(),predictions= val_out_index)\n",
        "sess = tf.Session()\n",
        "print(con_mat.eval(session=sess))\n",
        "#help(model1.evaluate)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "600\n",
            "600\n",
            "[[178  16   6]\n",
            " [  8 189   3]\n",
            " [  7   4 189]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}